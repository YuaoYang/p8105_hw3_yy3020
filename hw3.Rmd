---
title: "hw3_yy3020"
author: "YuaoYang"
date: "2019/10/13"
output: github_document
---

```{r}
library(patchwork)
library(tidyverse)
library(p8105.datasets)

knitr::opts_chunk$set(
  fig.width = 12,
  fig.asp = 1,
  out.width = "100%"
)

theme_set(theme_bw() + theme(legend.position = "right"))

```

# Problem 1

```{r}
data("instacart")
instacart
```
There are {`r nrow(instacart) `} observations and the structure of dataset is (`r nrow(instacart)`, `r ncol(instacart)`)in this dataset.
And the key variables are(`r colnames(instacart)`).  The fisrt row means the identifier is {`r instacart[1,1] `}, the product identifier is {`r instacart[1,2] `}, order in which this product was added to cart is {`r instacart[1,3] `}, and  this prodcut has been ordered by this user in the past by user id {`r instacart[1,5] `}, evaluation set this order belongs in {`r instacart[1,6] `},  the order sequence number for this user is {`r instacart[1,7] `}, the day of the week on this order was placed on {`r instacart[1,8] `} day,  the hour of the day on which the order is placed on {`r instacart[1,9] `}, days since the last order is {`r instacart[1,10] `}, the name of this product is {`r instacart[1,11] `}, the aisle identifier is {`r instacart[1,12] `}  and name is {`r instacart[1,14] `}which belongs to department {`r instacart[1,15] `} and the id of this department is {`r instacart[1,13] `}.

```{r}
aisle_new = instacart%>%
  group_by(aisle) %>%
  count() %>%
  arrange(n) 
most = pull(aisle_new[134, 1])

```
There are {`r length(pull(aisle_new, aisle)) `} aisles, and the most odered item is {`r most `}.

```{r}
 instacart%>%
  group_by(aisle) %>%
  count() %>%
filter(n >10000) %>%
 ggplot(aes(x = n, y =aisle)) +
  geom_point() +
 labs(
   title = "the number of items ordered which is more than 10000",
    x = "Numbers Of Items Odered",
    y = "Aisles"
   ) 

```
From the plot, we can find that the fresh vegetablea and fresh fruits are most odered items.
```{r}
instacart %>%
  filter(aisle %in% c('baking ingredients', 'dog food care', 'packaged vegetables fruits')) %>%
select(aisle, product_name) %>%
   group_by(aisle,product_name) %>%  
  count() %>% 
   group_by(aisle)%>%
  filter(min_rank(desc(n))<=3)%>%
  knitr::kable()
 
```

#From the table, I find the most ordered items are cane sugar, light brown sugar and pure baking soda in aisle baking ingredients.The most ordered items are organix chicken & brown rice recipe, small dog biscuits and snack sticks chicken &rice recioe dog treats in aisle dog food care. The most ordered items are organic baby spinach, organic blueberries, and organic raspberries in aisle packaged vagetables fruits.




```{r}

 instacart %>%
  filter( product_name  %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>%
  group_by(product_name, order_dow) %>%
 summarise( means = mean(order_hour_of_day)) %>%
  pivot_wider(id_cols = product_name ,
              names_from = order_dow,
              values_from = means) %>%
    knitr::kable()
  
```

#From the table, I find that in Coffee Ice Cream, the mean hour is concerning on afternoon from 13 to 15, and the mean hour is concerning on noon from 11 to 14.

#Problem 2


```{r}
data('brfss_smart2010') 
overall_health = brfss_smart2010 %>%
janitor::clean_names()  %>%
  filter(topic == "Overall Health") %>%
  filter(response %in% c("Poor", "Fair", "Good", "Very good", "Excellent")) %>%
  mutate(response = factor(response, level = c("Poor", "Fair", "Good", "Very good", "Excellent"))) %>%
    arrange(desc(response))

```
Try to tidy the dataset and concern on the overall health.

```{r}
overall_health %>%
  filter(year %in% c (2002, 2010)) %>%
  group_by(locationdesc, locationabbr,year) %>%
  count() %>%
  group_by(year,locationabbr)%>%
  count()%>%
  filter( n >= 7)
#first group_by the locationdesc, then group_by the locationabbr, then count the observation in each group.



```
In 2002, there are 6 states observed at 7 or more locations, but in 2010, the number of states increaes to 20.

```{r}
avg = overall_health %>%
  filter(response == "Excellent") %>%
  select(year, locationabbr, data_value) %>%
  group_by(year, locationabbr) %>%
  summarize(average_data_value = mean(data_value))
#summarize overwrite the original data, but mutate add new column of data if the name is not same as the original one

ggplot(avg, aes(x = year, y = average_data_value, color= locationabbr)) +
  geom_line() +
  labs(
    title = "Spaghetti plot"
    )
```
From the spaghetti plot, we can find that the range of average date value in  most of states is between 15 to 25.
```{r}
plot_2006 = overall_health %>%
  filter(year == 2006 & locationabbr == "NY") %>% 
  ggplot(aes(x = response,
        y = data_value,
     fill = locationdesc))+ geom_bar(stat = "identity", position=position_dodge()) +
  labs(
    title = "the data value in 2006 "
    )

plot_2010 = overall_health %>%
  filter(year == 2010 & locationabbr == "NY") %>% 
  ggplot(aes(x = response,
        y = data_value,
    fill = locationdesc))+ geom_bar(stat = "identity", position=position_dodge()) +
   labs(
    title = "the data value in 2010 "
    )


 plot_2006 + plot_2010
```
From the plot of 2006, we can find the data value is changed variously from poor to excellent, and the good and very good response have the higher value.
From the plot of 2010, the total trend is the same as it in 2016, the good and very good response have the higher value for the all countries.


#Problem 3

```{r}
accel_data = read_csv(file = "./accel_data.csv")
accel_data_tidy = read_csv(file = "./accel_data.csv")%>% 
  janitor::clean_names() %>%
  pivot_longer(4:1443, names_to = "activity",names_prefix = "activity_", values_to = "counts") %>%
   mutate(day = factor(day, level = c("Monday","Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"))) %>%
  select(week, day, activity, counts) %>%
  mutate(weekdayVSweekend = ifelse(day %in% c("Monday","Tuesday", "Wednesday", "Thursday", "Friday"),  "weekday", "weekend" )) 

```
There are {`r nrow(accel_data_tidy) `} observations and {`r ncol(accel_data_tidy) `} variables. And the names of  variables are {`r colnames(accel_data_tidy) `}.

```{r}
accel_data_tidy %>%
  group_by(week, day) %>%
  summarise(total = sum(counts)) %>%
  pivot_wider(names_from = day,
              values_from = total)%>%
      knitr::kable()


```


# From the table, we can find on Monday of week 1, the total activity is very low, and that total acticity in Saturday of week 4 and 5 is 1440, and maybe it makes fault.

```{r}
accel_data_tidy %>%
  mutate(
   activity = as.numeric(activity)) %>%
 mutate(
    hour=(activity) %/%60) %>%
  group_by(week, day, hour) %>%
  summarise(hour_activity = sum(counts)) %>%
ggplot( aes(x= hour, y=hour_activity, fill = day)) + geom_bar(stat = "identity",   position=position_dodge()) +
  labs(
    title = "24-hour activity  for each day",
    x = "24 hour",
    y = "one hour activity sum"
   ) 

```
From the plot, we can find that never mind which day in a week, this guy has lower activity from 23 to 5 clock, and the total trend shows that this guy has higher activity per hour from 18 to 21 clock, especailly, the highest activity at the noon of Monday.
